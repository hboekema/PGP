import colorsys
import os
from typing import Dict, List

import imageio
import matplotlib.pyplot as plt
import numpy as np
import torch
from pyquaternion import Quaternion
from vod.prediction.input_representation.agents import (
    AgentBoxesWithFadedHistory, AgentBoxesWithPast)
from vod.prediction.input_representation.combinators import Rasterizer
from vod.prediction.input_representation.interface import InputRepresentation
from vod.prediction.input_representation.static_layers import (
    StaticLayerRasterizer, color_by_yaw)
from vod.prediction.input_representation.utils import smooth_rotation

import train_eval.utils as u
from train_eval.initialization import (get_specific_args, initialize_dataset,
                                       initialize_prediction_model)

# from nuscenes.prediction.input_representation.agents import \
#    AgentBoxesWithFadedHistory
# from nuscenes.prediction.input_representation.combinators import Rasterizer
# from nuscenes.prediction.input_representation.interface import \
#    InputRepresentation
# from nuscenes.prediction.input_representation.static_layers import (
#    StaticLayerRasterizer, color_by_yaw)


# Initialize device:
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


def apply_rotation(traj2d, rotmat):
    traj3d = np.hstack([traj2d, np.zeros((traj2d.shape[0], 1))])
    traj3d_rot = np.dot(rotmat, traj3d.T).T

    return traj3d_rot[:, :2]


class Visualizer:
    """
    Class for visualizing predictions generated by trained model
    """

    def __init__(self, cfg: Dict, data_root: str, data_dir: str, checkpoint_path: str):
        """
        Initialize evaluator object
        :param cfg: Configuration parameters
        :param data_root: Root directory with data
        :param data_dir: Directory with extracted, pre-processed data
        :param checkpoint_path: Path to checkpoint with trained weights
        """

        # Initialize dataset
        ds_type = (
            cfg["dataset"]
            + "_"
            + cfg["agent_setting"]
            + "_"
            + cfg["input_representation"]
        )
        spec_args = get_specific_args(
            cfg["dataset"],
            data_root,
            cfg["version"] if "version" in cfg.keys() else None,
        )
        test_set = initialize_dataset(
            ds_type, ["load_data", data_dir, cfg["test_set_args"]] + spec_args
        )
        self.ds = test_set

        # Initialize model
        self.model = initialize_prediction_model(
            cfg["encoder_type"],
            cfg["aggregator_type"],
            cfg["decoder_type"],
            cfg["encoder_args"],
            cfg["aggregator_args"],
            cfg["decoder_args"],
        )
        self.model = self.model.float().to(device)
        self.model.eval()

        self.freq = 10

        # Load checkpoint
        # checkpoint = torch.load(checkpoint_path)
        # self.model.load_state_dict(checkpoint["model_state_dict"])

    def visualize(self, output_dir: str, dataset_type: str):
        """
        Generate visualizations for predictions
        :param output_dir: results directory to dump visualizations in
        :param dataset_type: e.g. 'nuScenes'. Visualizations will vary based on dataset.
        :return:
        """
        if dataset_type == "nuScenes":
            self.visualize_nuscenes(output_dir)
        elif dataset_type == "VOD":
            self.visualize_nuscenes(output_dir)
            # raise NotImplementedError

    def visualize_nuscenes(self, output_dir):
        index_list = self.get_vis_idcs_nuscenes()
        if not os.path.isdir(os.path.join(output_dir, "results", "gifs")):
            os.mkdir(os.path.join(output_dir, "results", "gifs"))
        for n, indices in enumerate(index_list):
            imgs = self.generate_nuscenes_gif(indices)
            filename = os.path.join(
                output_dir, "results", "gifs", "example" + str(n) + ".gif"
            )
            imageio.mimsave(filename, imgs, format="GIF", duration=(1000 / self.freq))

    def get_vis_idcs_nuscenes(self):
        """
        Returns list of list of indices for generating gifs for the nuScenes val set.
        """
        # token_list = get_prediction_challenge_split(
        #    "val", dataroot=self.ds.helper.data.dataroot
        # )
        idcs = [list(range(0, 60))]

        return idcs

    def vis_frame(self, idx, raster_maps):
        # Load data
        data = self.ds[idx]
        data = u.send_to_device(u.convert_double_to_float(u.convert2tensors(data)))
        i_t = data["inputs"]["instance_token"]
        s_t = data["inputs"]["sample_token"]

        # Get raster map
        hd_map = raster_maps.make_input_representation(i_t, s_t)
        r, g, b = (
            hd_map[:, :, 0] / 255,
            hd_map[:, :, 1] / 255,
            hd_map[:, :, 2] / 255,
        )
        hd_map_gray = 0.2989 * r + 0.5870 * g + 0.1140 * b

        # Predict
        predictions = self.model(data["inputs"])

        # Plot
        fig, ax = plt.subplots(1, 3, figsize=(15, 5))
        ax[0].imshow(hd_map, extent=self.ds.map_extent)
        ax[1].imshow(hd_map_gray, cmap="gist_gray", extent=self.ds.map_extent)
        ax[2].imshow(hd_map_gray, cmap="gist_gray", extent=self.ds.map_extent)

        for n, traj in enumerate(predictions["traj"][0]):
            ax[1].plot(
                traj[:, 0].detach().cpu().numpy(),
                traj[:, 1].detach().cpu().numpy(),
                lw=4,
                color="r",
                alpha=0.8,
            )
            ax[1].scatter(
                traj[-1, 0].detach().cpu().numpy(),
                traj[-1, 1].detach().cpu().numpy(),
                60,
                color="r",
                alpha=0.8,
            )

        traj_gt = data["ground_truth"]["traj"][0]
        ax[2].plot(
            traj_gt[:, 0].detach().cpu().numpy(),
            traj_gt[:, 1].detach().cpu().numpy(),
            lw=4,
            color="g",
        )
        ax[2].scatter(
            traj_gt[-1, 0].detach().cpu().numpy(),
            traj_gt[-1, 1].detach().cpu().numpy(),
            60,
            color="g",
        )

        ax[0].axis("off")
        ax[1].axis("off")
        ax[2].axis("off")
        fig.tight_layout(pad=0)
        ax[0].margins(0)
        ax[1].margins(0)
        ax[2].margins(0)

        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(
            fig.canvas.get_width_height()[::-1] + (3,)
        )

        plt.close(fig)
        return image_from_plot

    def generate_nuscenes_gif(self, idcs: List[int]):
        """
        Generates gif of predictions for the given set of indices.
        :param idcs: val set indices corresponding to a particular instance token.
        """

        # Raster maps for visualization.
        map_extent = self.ds.map_extent
        resolution = 0.1
        static_layer_rasterizer = StaticLayerRasterizer(
            self.ds.helper,
            resolution=resolution,
            meters_ahead=map_extent[3],
            meters_behind=-map_extent[2],
            meters_left=-map_extent[0],
            meters_right=map_extent[1],
        )

        agent_rasterizer = AgentBoxesWithFadedHistory(
            self.ds.helper,
            seconds_of_history=1,
            resolution=resolution,
            meters_ahead=map_extent[3],
            meters_behind=-map_extent[2],
            meters_left=-map_extent[0],
            meters_right=map_extent[1],
        )

        raster_maps = InputRepresentation(
            static_layer_rasterizer, agent_rasterizer, Rasterizer()
        )

        imgs = []
        for idx in idcs:
            image_from_plot = self.vis_frame(idx, raster_maps)
            imgs.append(image_from_plot)

        return imgs

    def generate_nuscenes_frame(self, idx: int):
        """
        Generates predictions for the given index.
        :param idx: index corresponding to a particular instance token.
        """

        # Raster maps for visualization.
        map_extent = self.ds.map_extent
        resolution = 0.1
        static_layer_rasterizer = StaticLayerRasterizer(
            self.ds.helper,
            resolution=resolution,
            meters_ahead=map_extent[3],
            meters_behind=-map_extent[2],
            meters_left=-map_extent[0],
            meters_right=map_extent[1],
        )

        agent_rasterizer = AgentBoxesWithFadedHistory(
            self.ds.helper,
            seconds_of_history=1,
            resolution=resolution,
            meters_ahead=map_extent[3],
            meters_behind=-map_extent[2],
            meters_left=-map_extent[0],
            meters_right=map_extent[1],
        )

        raster_maps = InputRepresentation(
            static_layer_rasterizer, agent_rasterizer, Rasterizer()
        )

        return self.vis_frame(idx, raster_maps)


class GeneralVisualizer:
    """
    Class for visualizing predictions generated by trained model
    """

    def __init__(self, helper):
        """
        Initialize evaluator object
        """

        self.freq = 10
        self.helper = helper

    def vis_frame_condensed(self, data, model, raster_maps, map_extent, k=10):
        # Load data
        data = u.send_to_device(u.convert_double_to_float(u.convert2tensors(data)))
        i_t = data["inputs"]["instance_token"]
        s_t = data["inputs"]["sample_token"]

        # Get raster map
        hd_map = raster_maps.make_input_representation(i_t, s_t)
        r, g, b = (
            hd_map[:, :, 0] / 255,
            hd_map[:, :, 1] / 255,
            hd_map[:, :, 2] / 255,
        )
        hd_map_gray = 0.2989 * r + 0.5870 * g + 0.1140 * b

        # Predict
        predictions = model(data["inputs"])
        traj_pred = predictions["traj"]
        probs = predictions["probs"]
        # sort trajectories by probability
        idcs = torch.argsort(probs, descending=True)
        # probs_new = probs[:, idcs[0]]
        traj_pred = traj_pred[0, idcs[0]].detach().cpu().numpy()

        traj_gt = data["ground_truth"]["traj"][0]
        traj_gt = traj_gt.detach().cpu().numpy()

        # correct orientation
        annotation = self.helper.get_sample_annotation(i_t, s_t)
        rotation = annotation["rotation"]
        smoothed_rotation = smooth_rotation(self.helper, i_t, s_t)

        orig_quaternion = Quaternion(rotation)
        smoothed_quaternion = Quaternion(smoothed_rotation)
        correction = smoothed_quaternion * orig_quaternion.conjugate
        R_correction = correction.rotation_matrix
        R_correction = np.linalg.inv(R_correction)

        traj_pred = apply_rotation(traj_pred, R_correction)
        traj_gt = apply_rotation(traj_gt, R_correction)

        # Plot
        fig, ax = plt.subplots(1, 1, figsize=(5, 5))
        ax.imshow(hd_map, extent=map_extent)

        for n, traj in enumerate(traj_pred[:k]):
            ax.plot(
                traj[:, 0],
                traj[:, 1],
                lw=4,
                color="r",
                alpha=0.8,
            )
            ax.scatter(
                traj[-1, 0],
                traj[-1, 1],
                60,
                color="r",
                alpha=0.8,
            )

        ax.plot(
            traj_gt[:, 0],
            traj_gt[:, 1],
            lw=4,
            color="g",
        )
        ax.scatter(
            traj_gt[-1, 0],
            traj_gt[-1, 1],
            60,
            color="g",
        )

        ax.axis("off")
        fig.tight_layout(pad=0)
        ax.margins(0)

        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(
            fig.canvas.get_width_height()[::-1] + (3,)
        )

        plt.close(fig)
        return image_from_plot

    def vis_frame(self, data, model, raster_maps, map_extent, k=10):
        # Load data
        data = u.send_to_device(u.convert_double_to_float(u.convert2tensors(data)))
        i_t = data["inputs"]["instance_token"]
        s_t = data["inputs"]["sample_token"]

        # Get raster map
        hd_map = raster_maps.make_input_representation(i_t, s_t)
        r, g, b = (
            hd_map[:, :, 0] / 255,
            hd_map[:, :, 1] / 255,
            hd_map[:, :, 2] / 255,
        )
        hd_map_gray = 0.2989 * r + 0.5870 * g + 0.1140 * b

        # Predict
        predictions = model(data["inputs"])
        traj_pred = predictions["traj"]
        probs = predictions["probs"]
        # sort trajectories by probability
        idcs = torch.argsort(probs, descending=True)
        # probs_new = probs[:, idcs[0]]
        traj_pred = traj_pred[0, idcs[0]]

        # Plot
        fig, ax = plt.subplots(1, 3, figsize=(15, 5))
        ax[0].imshow(hd_map, extent=map_extent)
        ax[1].imshow(hd_map_gray, cmap="gist_gray", extent=map_extent)
        ax[2].imshow(hd_map_gray, cmap="gist_gray", extent=map_extent)

        for n, traj in enumerate(traj_pred[:k]):
            ax[1].plot(
                traj[:, 0].detach().cpu().numpy(),
                traj[:, 1].detach().cpu().numpy(),
                lw=4,
                color="r",
                alpha=0.8,
            )
            ax[1].scatter(
                traj[-1, 0].detach().cpu().numpy(),
                traj[-1, 1].detach().cpu().numpy(),
                60,
                color="r",
                alpha=0.8,
            )

        traj_gt = data["ground_truth"]["traj"][0]
        ax[2].plot(
            traj_gt[:, 0].detach().cpu().numpy(),
            traj_gt[:, 1].detach().cpu().numpy(),
            lw=4,
            color="g",
        )
        ax[2].scatter(
            traj_gt[-1, 0].detach().cpu().numpy(),
            traj_gt[-1, 1].detach().cpu().numpy(),
            60,
            color="g",
        )

        ax[0].axis("off")
        ax[1].axis("off")
        ax[2].axis("off")
        fig.tight_layout(pad=0)
        ax[0].margins(0)
        ax[1].margins(0)
        ax[2].margins(0)

        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(
            fig.canvas.get_width_height()[::-1] + (3,)
        )

        # plt.show()
        plt.close(fig)
        return image_from_plot

    def generate_frame(self, sample, model, helper, map_extent):
        """
        Generates predictions for the given sample and model.
        """
        colors = np.array([(255, 255, 255), (119, 136, 153), (0, 0, 255)])
        colors_norm = colors / 255
        colors_hsv = np.array([colorsys.rgb_to_hsv(*color) for color in colors_norm])
        colors_hsv[:, 1] /= 4
        colors = np.array([colorsys.hsv_to_rgb(*color) for color in colors_hsv]) * 255
        colors = colors.tolist()

        # Raster maps for visualization.
        resolution = 0.01
        static_layer_rasterizer = StaticLayerRasterizer(
            helper,
            resolution=resolution,
            colors=colors,
            meters_ahead=map_extent[3],
            meters_behind=-map_extent[2],
            meters_left=-map_extent[0],
            meters_right=map_extent[1],
        )

        # agent_rasterizer = AgentBoxesWithFadedHistory(
        agent_rasterizer = AgentBoxesWithPast(
            helper,
            seconds_of_history=0.5,
            resolution=resolution,
            meters_ahead=map_extent[3],
            meters_behind=-map_extent[2],
            meters_left=-map_extent[0],
            meters_right=map_extent[1],
        )

        raster_maps = InputRepresentation(
            static_layer_rasterizer, agent_rasterizer, Rasterizer()
        )

        # return self.vis_frame(sample, model, raster_maps, map_extent)
        return self.vis_frame_condensed(sample, model, raster_maps, map_extent)

    def visualize_graph(
        self, node_feats, s_next, edge_type, evf_gt, node_seq, fut_xy, map_extent
    ):
        """
        Function to visualize lane graph.
        """
        fig, ax = plt.subplots()
        ax.imshow(np.zeros((3, 3)), extent=map_extent, cmap="gist_gray")

        # Plot edges
        for src_id, src_feats in enumerate(node_feats):
            feat_len = np.sum(np.sum(np.absolute(src_feats), axis=1) != 0)

            if feat_len > 0:
                src_x = np.mean(src_feats[:feat_len, 0])
                src_y = np.mean(src_feats[:feat_len, 1])

                for idx, dest_id in enumerate(s_next[src_id]):
                    edge_t = edge_type[src_id, idx]
                    visited = evf_gt[src_id, idx]
                    if 3 > edge_t > 0:

                        dest_feats = node_feats[int(dest_id)]
                        feat_len_dest = np.sum(
                            np.sum(np.absolute(dest_feats), axis=1) != 0
                        )
                        dest_x = np.mean(dest_feats[:feat_len_dest, 0])
                        dest_y = np.mean(dest_feats[:feat_len_dest, 1])
                        d_x = dest_x - src_x
                        d_y = dest_y - src_y

                        line_style = "-" if edge_t == 1 else "--"
                        width = 2 if visited else 0.01
                        alpha = 1 if visited else 0.5

                        plt.arrow(
                            src_x,
                            src_y,
                            d_x,
                            d_y,
                            color="w",
                            head_width=0.1,
                            length_includes_head=True,
                            linestyle=line_style,
                            width=width,
                            alpha=alpha,
                        )

        # Plot nodes
        for node_id, node_feat in enumerate(node_feats):
            feat_len = np.sum(np.sum(np.absolute(node_feat), axis=1) != 0)
            if feat_len > 0:
                visited = node_id in node_seq
                x = np.mean(node_feat[:feat_len, 0])
                y = np.mean(node_feat[:feat_len, 1])
                yaw = np.arctan2(
                    np.mean(np.sin(node_feat[:feat_len, 2])),
                    np.mean(np.cos(node_feat[:feat_len, 2])),
                )
                c = color_by_yaw(0, yaw)
                c = np.asarray(c).reshape(-1, 3) / 255
                s = 200 if visited else 50
                ax.scatter(x, y, s, c=c)

        plt.plot(fut_xy[:, 0], fut_xy[:, 1], color="r", lw=3)

        plt.show()
